{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Подгружаем данные в ~/Desktop, чтобы не менять ссылку в коде\n",
    "# !cd ~/Desktop\n",
    "# !wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1IpNZQfchwcGRGZdhbXU4ynpD9py5TDrh' -O data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, \\\n",
    "GradientBoostingRegressor, StackingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, RobustScaler, MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool, cv, FeaturesData\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем DataFrame из скачанных данных (берем последний json, так как в нем максимальное количество собранной\n",
    "# информации)\n",
    "# собирается долго - около 2 часов\n",
    "# после первой сборки - этот блок не нужен\n",
    "\n",
    "# data = pd.DataFrame()\n",
    "# files = os.listdir('../../../Desktop/data/')\n",
    "# with open('../../../Desktop/data/' + files[-1], 'r') as f:\n",
    "#     new_dict = {}\n",
    "#     new_dict = json.loads(f.read(), encoding='mac_cyrillic')\n",
    "#     df = pd.DataFrame()\n",
    "#     i = 0\n",
    "#     for key, val in tqdm(new_dict.items()):\n",
    "#         df.loc[i,'link'] = key\n",
    "#         for k, v in val.items():\n",
    "#             df.loc[i,k] = v\n",
    "#         i += 1\n",
    "#     data = pd.concat([data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем собранный датасет на диск - чтобы каждый раз не собирать по 2 часа \n",
    "# data.to_csv('~/Desktop/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные, сохраненные на прошлом шаге (так как уже все собрано - начинаем сразу отсюда)\n",
    "data = pd.read_csv('~/Desktop/data.csv', index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                    0\n",
       "year                 2208\n",
       "kmAge                2554\n",
       "bodytype             2218\n",
       "color                2208\n",
       "engine               2210\n",
       "transportTax        24268\n",
       "transmission         2419\n",
       "drive                2575\n",
       "wheel                2554\n",
       "state                2554\n",
       "ownersCount          2717\n",
       "pts                  2704\n",
       "owningTime          57226\n",
       "customs              2554\n",
       "vin                  4640\n",
       "licensePlate        21763\n",
       "model_name          20956\n",
       "price               20956\n",
       "price_change        90187\n",
       "publication_date     2208\n",
       "views                2554\n",
       "photo_count          2208\n",
       "official_dealer     87679\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cмотрим на пропуски в полях\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем те поля, где слишком много пропусков\n",
    "\n",
    "data.drop(['transportTax','owningTime', 'licensePlate','price_change', 'official_dealer'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# убираем редкие данные, которые портят в итоге модель\n",
    "\n",
    "data.drop(data[data.state!='Не требует ремонта'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data.wheel=='Правый'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('~/Downloads/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обрабатываем столбцы датасета. Если данных нет - возвращаем None\n",
    "\n",
    "# переводим год в числовой формат (везде float для catboost FeaturesData)\n",
    "def get_car_type(link_row):\n",
    "    return link_row.split('/')[3]\n",
    "\n",
    "def to_int_year(year_row):\n",
    "    return float(year_row)\n",
    "\n",
    "# переводим километраж в числовой формат\n",
    "def to_int_km(kmAge_row):\n",
    "    if not kmAge_row:\n",
    "        return None\n",
    "    regex = re.compile('\\d+')\n",
    "    cleaned_row = ''.join(regex.findall(kmAge_row)[0])\n",
    "    return float(cleaned_row)\n",
    "\n",
    "def fix_views(views_row):\n",
    "    if '№' in views_row:\n",
    "        return None\n",
    "    regex = re.compile('\\d+')\n",
    "    cleaned_row = float(regex.search(views_row)[0])\n",
    "    return cleaned_row\n",
    "\n",
    "# разбиваем на 3 колонки информацию по двигателю (объем, мощность в л.с. и тип топлива)\n",
    "def split_engine_col(engine_row):\n",
    "    volume = None\n",
    "    horse_power = None\n",
    "    fuel_type = None\n",
    "    if engine_row == None:\n",
    "        return volume, horse_power, fuel_type\n",
    "    \n",
    "    params = engine_row.split('/')\n",
    "    params_num = len(params)\n",
    "    for p in params:\n",
    "        if ('бензин' in p.lower()) or ('дизел' in p.lower()) or ('газ' in p.lower()):\n",
    "            fuel_type = p\n",
    "        if 'л.' in p.lower():\n",
    "            regex = re.compile('\\d+')\n",
    "            horse_power = float(''.join(regex.findall(p)))\n",
    "        if ' л' in p:\n",
    "            regex = re.compile('\\d+\\.\\d+')\n",
    "            volume = float(''.join(regex.findall(p)))\n",
    "    return [volume, horse_power, fuel_type]\n",
    "\n",
    "# корректируем 'кракозябры' в птс\n",
    "def fix_pts(pts_row):\n",
    "    pts_list = ['Оригинал', 'Дубликат']\n",
    "    if pts_row not in pts_list:\n",
    "        return 'Оригинал'\n",
    "    return 'Оригинал'\n",
    "\n",
    "# достаем число владельцев\n",
    "def fix_ownersCount(ownersCount_row):\n",
    "    owners_list = ['3 или более', '2 владельца', '1 владелец']\n",
    "    if not ownersCount_row:\n",
    "        return None\n",
    "    if ownersCount_row.replace('\\xa0', ' ') not in owners_list:\n",
    "        ownersCount_row = '3 или более'\n",
    "    return float(ownersCount_row[0])\n",
    "\n",
    "# общая функция для очистки данных от неправильного кодирования\n",
    "def fix_bad_encoding(row):\n",
    "    if not row:\n",
    "        return None\n",
    "    if 'Ð' in row:\n",
    "        return None\n",
    "    return row\n",
    "\n",
    "# очищаем цену от байтовых разделителей (где-то нужно было с кодировкой поработать, но - поезд ушел :) )\n",
    "def fix_price(price_row):\n",
    "    try:\n",
    "        return float(price_row[:-1].replace('\\xa0', ''))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# расчет транспортного налога - в итоге не нужно\n",
    "def count_transport_tax(engine_hp_row):\n",
    "    if engine_hp_row <100:\n",
    "        return engine_hp_row*25\n",
    "    elif engine_hp_row <150:\n",
    "        return engine_hp_row*35\n",
    "    elif engine_hp_row <200:\n",
    "        return engine_hp_row*50\n",
    "    elif engine_hp_row <250:\n",
    "        return engine_hp_row*75\n",
    "    else:\n",
    "        return engine_hp_row*150\n",
    "\n",
    "# переводим дату публикации в формат unix-timestamp\n",
    "def calculate_publ_date(publication_date):\n",
    "    month_dict = {\n",
    "        'января' : '01',\n",
    "        'февраля' : '02',\n",
    "        'марта' : '03',\n",
    "        'апреля' : '04',\n",
    "        'мая' : '05',\n",
    "        'июня' : '06',\n",
    "        'июля' : '07',\n",
    "        'августа' : '08',\n",
    "        'сентября' : '09',\n",
    "        'октября' : '10',\n",
    "        'ноября' : '11',\n",
    "        'декабря' : '12',\n",
    "    }\n",
    "    \n",
    "    i = 1\n",
    "    for key in month_dict:\n",
    "        if key in publication_date:\n",
    "            break\n",
    "        i += 1\n",
    "        if i > 12:\n",
    "            return None\n",
    "    regex = re.compile('\\d{4}')\n",
    "    year_match = regex.search(publication_date)\n",
    "    if not year_match:\n",
    "        year = ' 2020'\n",
    "        publication_date = publication_date + year\n",
    "    \n",
    "    for key in month_dict:\n",
    "        if key in publication_date:\n",
    "            pub_date = publication_date.replace(key, month_dict[key])    \n",
    "    date = datetime.strptime(pub_date, '%d %m %Y').timestamp()\n",
    "    return date\n",
    "\n",
    "# достаем название бренда, модели и модификации из поля model_name\n",
    "def split_brand_model(model_row):\n",
    "    fix_list = [\n",
    "    '«Чайка»',\n",
    "    '«Волга»',\n",
    "    'Siber',\n",
    "    '«Победа»',\n",
    "    'Defender',\n",
    "    'Discovery',\n",
    "    'Freelander',\n",
    "    'Range Rover',\n",
    "    'Granta',\n",
    "    'Kalina',\n",
    "    'Largus',\n",
    "    'Priora',\n",
    "    'Vesta',\n",
    "    'Vitara',\n",
    "    'Picasso',\n",
    "    'Cherokee',\n",
    "    'Series',\n",
    "    'WRX',\n",
    "    'Lancaster',\n",
    "    '(ВАЗ)',\n",
    "    ]\n",
    "    brand, model, modif = model_row.split()[0].strip(), model_row.split()[1].strip(), ' '.join(model_row.split()[2:])\n",
    "    if brand == 'Land':\n",
    "        brand += ' Rover'\n",
    "        model = model.replace('Rover', '').strip()\n",
    "    \n",
    "    modif = modif.strip()\n",
    "    for part in fix_list:\n",
    "        if part in modif:\n",
    "            modif = modif.replace(part, '').strip()\n",
    "            model = (model + ' ' + part).strip()\n",
    "    return [brand, model, modif]\n",
    "\n",
    "def fix_vin(vin_row):\n",
    "    if not vin_row:\n",
    "        return 'other'\n",
    "    return vin_row.replace('*', '')\n",
    "\n",
    "# # достаем номер региона рег номера - поле далее убрано, ухудшает метрики данных\n",
    "# def fix_license_plate(licensePlate_row):\n",
    "#     if not licensePlate_row:\n",
    "#         return None\n",
    "#     return licensePlate_row.split('|')[1]\n",
    "\n",
    "# функция, суммирующая все предыдущие\n",
    "def clear_data(data_df):\n",
    "    data_new = pd.DataFrame()\n",
    "    \n",
    "    data_new['car_type'] = data_df['link'].map(get_car_type)\n",
    "    data_new['year'] = data_df['year'].apply(to_int_year)\n",
    "    data_new['kmAge'] = data_df['kmAge'].apply(to_int_km)\n",
    "    \n",
    "    # гипотеза, что убывающие функции по году и пробегу сработала - добавляем поля\n",
    "#     data_new['inv_year'] = np.exp(-0.48*data_df['year'].apply(to_int_year))\n",
    "#     data_new['inv_kmAge'] = np.exp(-0.48*data_df['kmAge'].apply(to_int_km))\n",
    "\n",
    "    data_new['inv_year'] = -np.log(data_df['year'].apply(to_int_year))\n",
    "    data_new['inv_kmAge'] = -np.log(data_df['kmAge'].apply(to_int_km))\n",
    "\n",
    "    data_new['drive'] = data_df['drive']\n",
    "    data_new['bodytype'] = data_df['bodytype'].apply(fix_bad_encoding)\n",
    "    data_new['color'] = data_df['color'].apply(fix_bad_encoding)\n",
    "    \n",
    "    # делаем сразу 3 поля\n",
    "    engine_data = pd.DataFrame(data_df['engine'].apply(split_engine_col).tolist(), \n",
    "                               columns=['engine_vol','engine_hp','engine_fuel'],\n",
    "                               index=data_df.index)\n",
    "    data_new = pd.concat([data_new, engine_data], axis=1)\n",
    "    \n",
    "    data_new['transport_tax'] = data_new['engine_hp'].apply(count_transport_tax)\n",
    "    \n",
    "    data_new['transmission'] = data_df['transmission'].apply(fix_bad_encoding)\n",
    "    data_new['ownersCount'] = data_df['ownersCount'].apply(fix_ownersCount)\n",
    "    data_new['model_name'] = data_df['model_name'].apply(fix_bad_encoding)\n",
    "    data_new['price'] = data_df['price'].apply(fix_price)\n",
    "    data_new['publication_date'] = data_df['publication_date'].apply(calculate_publ_date)\n",
    "    \n",
    "    data_new['vin'] = data_df['vin'].apply(fix_vin)\n",
    "    data_new['pts'] = data_df['pts'].apply(fix_pts)\n",
    "    \n",
    "    data_new['photo_count'] = data_df['photo_count']\n",
    "    not_na_cols = ['year', 'kmAge', 'model_name', 'price']\n",
    "    \n",
    "    # делаем сразу 3 поля\n",
    "    brand_model = pd.DataFrame(data_df['model_name'].apply(split_brand_model).tolist(), \n",
    "                               columns=['brand','model','modification'],\n",
    "                               index=data_df.index)\n",
    "    data_new = pd.concat([data_new, brand_model], axis=1)\n",
    "    data_new['km_per_year'] = data_new['kmAge']/(2020 - data_new['year'].apply(lambda x: x if x!=2020 else 2019))\n",
    "    data_new['km_per_owner'] = data_new['kmAge']/data_new['ownersCount']\n",
    "    data_new['publ_since'] = datetime.timestamp(datetime.now()) - data_new['publication_date']\n",
    "    data_new[['engine_vol', 'engine_hp']].fillna(data_new[['engine_vol', 'engine_hp']].mean(), inplace=True)\n",
    "    data_new['hp_per_vol'] = data_new['engine_hp']/data_new['engine_vol']\n",
    "    data_new['views'] = data_df['views'].apply(fix_views)\n",
    " \n",
    "    data_new.dropna(subset=not_na_cols, inplace=True)\n",
    "    data_new.drop(data_new[data_new['photo_count']<4].index, inplace=True)\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksim/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "# очищенный датасет\n",
    "final_data = clear_data(data).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# числовые и категориальные столбцы\n",
    "\n",
    "num_features = [\n",
    "                'year', \n",
    "                'kmAge',\n",
    "                'inv_year',\n",
    "                'inv_kmAge',\n",
    "                'engine_vol', \n",
    "                'engine_hp',\n",
    "                'ownersCount',\n",
    "                'publication_date', \n",
    "                'photo_count', \n",
    "                'km_per_year', \n",
    "#                 'km_per_owner', # - портит модель\n",
    "                'publ_since', \n",
    "                'hp_per_vol', \n",
    "                'views'\n",
    "               ]\n",
    "\n",
    "cat_features = ['car_type', \n",
    "                'bodytype', \n",
    "                'color', \n",
    "                'drive',\n",
    "                'engine_fuel', \n",
    "                'transmission', \n",
    "                'brand',\n",
    "                'model',\n",
    "                'model_name',\n",
    "                'modification',\n",
    "                'pts',\n",
    "                'vin',\n",
    "               ]\n",
    "\n",
    "\n",
    "# выделяем признаки\n",
    "X = final_data.drop(['price'], axis=1)\n",
    "# считаем средние значения и самые частотные значения для числовых и категориальных данных\n",
    "# numeric_features_mean = final_data[numeric_features].mean().astype('float32')\n",
    "# cat_features_mostfreq = final_data[cat_features].mode(0).iloc[0]\n",
    "\n",
    "# заполняем пустоты средними значениями для числовых данных\n",
    "# заполняем пустоты наиболее частотными значениями для категориальных данных\n",
    "\n",
    "# выделяем target\n",
    "y = final_data.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем индексы выбросов для каждой колонки\n",
    "\n",
    "def outliers_iqr(ys):\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return ys[(ys > upper_bound) | (ys < lower_bound)].index\n",
    "\n",
    "# объединяем индексы\n",
    "outliers_index_list = []\n",
    "columns = list(X[num_features].columns)\n",
    "for col in columns:\n",
    "    outliers_idx = outliers_iqr(final_data[col])\n",
    "    outliers_index_list += list(outliers_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ручная чистка от выбросов - решения sklern типа DBScan, Isolated tree и др не дали хороших результатов\n",
    "\n",
    "\n",
    "# находим индексы раритетных авто\n",
    "# year_outliers_indx = list(X.year[X.year < 1980.0].index)\n",
    "\n",
    "# находим индексы выбросов с очень большим пробегом\n",
    "kmAge_peaks_indx = list(X.kmAge[X.kmAge > 80e4].index)\n",
    "\n",
    "# убираем редкие нецелевые виды кузова\n",
    "bodytype_names = X.bodytype.value_counts().iloc[12:].index\n",
    "bodytype_outliers = ['тент', 'промтоварный автофургон', 'изотермический фургон',\n",
    "       'рефрижератор', 'бортовой грузовик',\n",
    "       'купе-хардтоп', 'внедорожник открытый', 'эвакуатор',\n",
    "       'фургон для торговли', 'скорая помощь',\n",
    "       'кэмпер', 'микровэн', 'тарга', 'седан-хардтоп',\n",
    "       'шасси', 'самосвал', 'лимузин', 'цистерна',\n",
    "       'самосвал с 2-х разгрузкой',\n",
    "        'цельнометаллический фургон',\n",
    "        'пикап одинарная кабина', 'пикап', 'родстер']\n",
    "\n",
    "bodytype_outliers_index = list(X[X.bodytype.isin(bodytype_outliers)].index)\n",
    "\n",
    "# rare_model_index = list(Xy.model_name[Xy.model_name.map(Xy.model_name.value_counts())<4].index)\n",
    "\n",
    "# находим индексы выбросов по объему двигателя\n",
    "engine_hp_outliers_indx = list(X.engine_hp[(X.engine_hp < 50) | (X.engine_hp > 1500)].index)\n",
    "\n",
    "# находим индексы очень редких видов топлива\n",
    "engine_fuel_outliers = list(X.engine_fuel.value_counts().iloc[2:].index)\n",
    "engine_fuel_outliers_index = list(X[X.engine_fuel.isin(engine_fuel_outliers)].index)\n",
    "\n",
    "# находим индексы ошибочных объемов\n",
    "engine_vol_outliers_indx = list(X.engine_vol[(X.engine_vol > 7.0) | (X.engine_vol < 0.5)].index)\n",
    "\n",
    "# находим устаревший редкий термин трансмиссии - видимо старая категория на авто.ру\n",
    "transmission_outliers_indx = list(X.transmission[X.transmission == 'робот'].index)\n",
    "\n",
    "# ошибочная цена в 68 000 000 за какой-то Форд Куга...\n",
    "price_outliers_index = list(y[(y>3e7)].index)# | (y<1e5)].index)\n",
    "\n",
    "# публикации, которые были сделаны до 2016 года - тоже убираем\n",
    "pub_date_outliers_index = list(X[X.publication_date < 1451595600.0].index)\n",
    "\n",
    "drive_outliers_index = list(final_data[final_data.drive.isin(['полный подключаемый', \n",
    "                                          'заднеприводный с подключаемым передним',\n",
    "                                          'постоянный привод на все колеса'])].index)\n",
    "\n",
    "# vin_outliers_index = list(X_cleaned[X_cleaned['vin'].map(X_cleaned.vin.value_counts()<10)==True].index)\n",
    "\n",
    "# суммируем все индексы\n",
    "outliers_indx = list(set(bodytype_outliers_index + transmission_outliers_indx + engine_hp_outliers_indx +\n",
    "                        price_outliers_index + engine_fuel_outliers_index + engine_vol_outliers_indx + \n",
    "                        pub_date_outliers_index  + outliers_index_list + engine_vol_outliers_indx + \n",
    "                        kmAge_peaks_indx)) #+ vin_outliers_index))\n",
    "\n",
    "# итогам первых прогонов - поля ниже - портят данные, без них метрики лучше\n",
    "# вычищаем все данные с индексами = outlier index\n",
    "X_cleaned = X.drop(outliers_indx)\n",
    "\n",
    "# вычищаем все данные с индексами = outlier index\n",
    "\n",
    "# логарифмируем target - лучшие показатели именно на логарифме\n",
    "y_cleaned = y.drop(outliers_indx).apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x187021610>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target после логарифмирования - \"купол\" и совсем другие данные по MAPE\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "y_cleaned.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка категориальных признаков через mean/count encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price_mean_count(df_mean_train, df_mean_test, col, df_train, df_test, group_cols=None):\n",
    "    \n",
    "    # функция добавляет в df_mean_train и df_mean_test столбцы средней цены/количества объявлений\n",
    "    # для каждого категориального признака col. group_cols - лист с дополнительными признаками,\n",
    "    # которые позволяют группировать цены/количества объявлений по связке \"признаки group_cols + признак col\"\n",
    "    \n",
    "    join_cols = []\n",
    "    \n",
    "    if (group_cols!=None) and (col not in group_cols):\n",
    "        join_cols.append(col) \n",
    "        join_cols += group_cols\n",
    "    else:\n",
    "        join_cols.append(col)\n",
    "    \n",
    "    df_mean_train[col+'_price_mean'] = df_train[join_cols].merge(df_train.groupby(by=join_cols, as_index=False).\n",
    "                                                                 price.median(), on=join_cols, how='left').iloc[:,-1]\n",
    "    df_mean_test[col+'_price_mean'] = df_test[join_cols].merge(df_train.groupby(by=join_cols, as_index=False).\n",
    "                                                               price.median(), on=join_cols, how='left').iloc[:,-1]\n",
    "    df_mean_train[col+'_count'] = df_train[join_cols].merge(df_train.groupby(by=join_cols, as_index=False).\n",
    "                                                            price.count(), on=join_cols, how='left').iloc[:,-1]\n",
    "    df_mean_test[col+'_count'] = df_test[join_cols].merge(df_train.groupby(by=join_cols, as_index=False).\n",
    "                                                          price.count(), on=join_cols, how='left').iloc[:,-1]   \n",
    "    \n",
    "    if col == 'model': \n",
    "        df_mean_test[col+'_price_mean'] = df_mean_test[col+'_price_mean'].\\\n",
    "        fillna(df_mean_test['brand_price_mean']) \n",
    "        \n",
    "        df_mean_test[col+'_count'] = df_mean_test[col+'_count'].\\\n",
    "        fillna(df_mean_test['brand_count'])\n",
    "    \n",
    "    if col == 'model_name':\n",
    "        df_mean_test[col+'_price_mean'] = df_mean_test[col+'_price_mean'].\\\n",
    "        fillna(df_mean_test['model_price_mean']).\\\n",
    "        fillna(df_mean_test['brand_price_mean'])    \n",
    "        \n",
    "        df_mean_test[col+'_count'] = df_mean_test[col+'_count'].\\\n",
    "        fillna(df_mean_test['model_count']).\\\n",
    "        fillna(df_mean_test['brand_count'])  \n",
    "    \n",
    "    if col == 'modification':\n",
    "        df_mean_test[col+'_price_mean'] = df_mean_test[col+'_price_mean'].\\\n",
    "        fillna(df_mean_test['model_name_price_mean']).fillna(df_mean_test['model_price_mean']).\\\n",
    "        fillna(df_mean_test['brand_price_mean'])    \n",
    "        \n",
    "        df_mean_test[col+'_count'] = df_mean_test[col+'_count'].\\\n",
    "        fillna(df_mean_test['model_name_count']).fillna(df_mean_test['model_count']).\\\n",
    "        fillna(df_mean_test['brand_count'])\n",
    "        \n",
    "        \n",
    "    other_filler_price_mean = df_mean_test[f'{col}_price_mean'].median()\n",
    "    df_mean_test[f'{col}_price_mean'] = df_mean_test[f'{col}_price_mean'].fillna(other_filler_price_mean)\n",
    "\n",
    "    other_filler_count = df_mean_test[f'{col}_count'].median()\n",
    "    df_mean_test[f'{col}_count'] = df_mean_test[f'{col}_count'].fillna(other_filler_count)\n",
    "\n",
    "\n",
    "\n",
    "def make_num_feat_mean(df_mean_train, df_mean_test, col, num_col, df_train, df_test, group_cols=None):\n",
    "    \n",
    "    # аналогичная функция, но кодирует категориальные признаки по средним значениям числовых колонок (num_features)\n",
    "    \n",
    "    if col in ['brand', 'model', 'model_name']:\n",
    "        join_cols = []\n",
    "\n",
    "        if (group_cols!=None) and (col not in group_cols):\n",
    "            join_cols.append(col) \n",
    "            join_cols += group_cols\n",
    "        else:\n",
    "            join_cols.append(col)\n",
    "\n",
    "        df_mean_train[f'{col}_{num_col}_mean'] = df_train[join_cols].merge(df_train.groupby(by=join_cols, as_index=False)\\\n",
    "                                                               [num_col].mean(), on=join_cols, how='left').iloc[:,-1]\n",
    "\n",
    "        df_mean_test[f'{col}_{num_col}_mean'] = df_test[join_cols].merge(df_train.groupby(by=join_cols, as_index=False)\\\n",
    "                                                               [num_col].mean(), on=join_cols, how='left').iloc[:,-1]\n",
    "\n",
    "        if col == 'model': \n",
    "            df_mean_test[f'{col}_{num_col}_mean'] = df_mean_test[f'{col}_{num_col}_mean'].\\\n",
    "            fillna(df_mean_test[f'brand_{num_col}_mean']) \n",
    "\n",
    "        if col == 'model_name':\n",
    "            df_mean_test[f'{col}_{num_col}_mean'] = df_mean_test[f'{col}_{num_col}_mean'].\\\n",
    "            fillna(df_mean_test[f'model_{num_col}_mean']).\\\n",
    "            fillna(df_mean_test[f'brand_{num_col}_mean'])    \n",
    "\n",
    "        if col == 'modification':\n",
    "            df_mean_test[f'{col}_{num_col}_mean'] = df_mean_test[f'{col}_{num_col}_mean'].\\\n",
    "            fillna(df_mean_test[f'model_name_{num_col}_mean']).fillna(df_mean_test[f'model_{num_col}_mean']).\\\n",
    "            fillna(df_mean_test[f'brand_{num_col}_mean'])    \n",
    "\n",
    "        other_filler = df_mean_test[f'{col}_{num_col}_mean'].median()\n",
    "        df_mean_test[f'{col}_{num_col}_mean'] = df_mean_test[f'{col}_{num_col}_mean'].fillna(other_filler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для обучения брал выборки в 5-10%\n",
    "X_cleaned_sample = X_cleaned.sample(frac=0.99, random_state=42)\n",
    "y_cleaned_sample = y_cleaned.sample(frac=0.99, random_state=42)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "poly = PolynomialFeatures() # PolyFeatures не помогают, как показала практика\n",
    "\n",
    "X_poly = poly.fit_transform(X_cleaned_sample[num_features])\n",
    "\n",
    "X_num = X_cleaned_sample[num_features]\n",
    "\n",
    "# OHE для категориальных данных - плохо работают\n",
    "# main_cat_features = cat_features[4:7]\n",
    "# X_cat_ohe = encoder.fit_transform(X_cleaned_sample[main_cat_features])\n",
    "\n",
    "# polyfeatures работают плохо - не используем\n",
    "# X = hstack((X_num, X_cat_ohe))\n",
    "\n",
    "X = X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хотел сделать через cross_val - но target нужно вытаскивать из логарифма, поэтому scoring получается кастомный\n",
    "# как сделать cross_val на кастомном scoring - пока не умею\n",
    "# поэтому делаем православный train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cleaned_sample, \n",
    "                                                    test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем индексы train и test выборок\n",
    "train_idx = y_train.index.values\n",
    "test_idx = y_test.index.values\n",
    "\n",
    "# добавляем таргет и получаем 2 выборки \"признак=таргет\"\n",
    "df_train = pd.concat([X_cleaned_sample, y_cleaned_sample], axis=1).loc[train_idx]\n",
    "df_test = pd.concat([X_cleaned_sample, y_cleaned_sample], axis=1).loc[test_idx]\n",
    "\n",
    "# пустые фреймы для mean/count encoding features\n",
    "df_mean_train = pd.DataFrame()\n",
    "df_mean_test = pd.DataFrame()\n",
    "\n",
    "# создаем кодированные категориальные признаки\n",
    "for col in cat_features:\n",
    "    make_price_mean_count(df_mean_train, df_mean_test, col, df_train, df_test, group_cols=None)\n",
    "    for num_col in num_features[:3]:\n",
    "        make_num_feat_mean(df_mean_train, df_mean_test, col, num_col, df_train, df_test, group_cols=['brand'])\n",
    "        \n",
    "mean_columns = df_mean_test.columns\n",
    "\n",
    "# если стэковать OHE, то нужна scipy.sparse.hstack, \n",
    "# если OHE не использовать - то стыковка через np.hstack\n",
    "if 'sparse' in str(type(X_train)):\n",
    "    X_train = hstack([X_train, df_mean_train])\n",
    "    X_test = hstack([X_test, df_mean_test])\n",
    "else:\n",
    "    X_train = np.hstack([X_train, df_mean_train])\n",
    "    X_test = np.hstack([X_test, df_mean_test])\n",
    "\n",
    "# скелим данные для линейных методов\n",
    "scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем блендинг\n",
    "\n",
    "ests = {\n",
    "'cat': CatBoostRegressor(depth=7, iterations=10000, learning_rate=0.03, verbose=False, random_state=42),\n",
    "'xgb' : XGBRegressor(n_estimators=10000, max_depth=3, learning_rate=0.05, random_state=42),\n",
    "'gb' : GradientBoostingRegressor(n_estimators=5000, max_depth=3, learning_rate=0.07, random_state=42),\n",
    "}\n",
    "    \n",
    "y_pred_dict = {}\n",
    "mape_dict = {}\n",
    "for est in ests:\n",
    "    ests[est].fit(X_train, y_train)\n",
    "    y_pred = ests[est].predict(X_test)\n",
    "    y_pred_dict.update({est:y_pred})\n",
    "\n",
    "    # считаем словарь эстиматор-mape, восстанавливая target из логарифма\n",
    "    mape = (abs(np.exp(y_pred) - np.exp(y_test))/np.exp(y_test)).mean()\n",
    "    mape_dict.update({est:mape})\n",
    "\n",
    "# Catboost можно использовать с помощью FeaturesData/Pool - с моим неумением тюнить CatBoost разницы не увидел\n",
    "\n",
    "# X_cleaned_sample = X_cleaned.sample(frac=0.99, random_state=42)\n",
    "# y_cleaned_sample = y_cleaned.sample(frac=0.99, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_cleaned_sample, y_cleaned_sample, test_size=0.3, shuffle=True)\n",
    "\n",
    "# X_train_fd = FeaturesData(num_feature_data=X_train[numeric_features].values, \n",
    "#                           cat_feature_data=X_train[cat_features].values,\n",
    "#                           num_feature_names=numeric_features,\n",
    "#                           cat_feature_names=cat_features)\n",
    "# X_test_fd = FeaturesData(num_feature_data=X_test[numeric_features].values, \n",
    "#                          cat_feature_data=X_test[cat_features].values,\n",
    "#                          num_feature_names=numeric_features,\n",
    "#                          cat_feature_names=cat_features)\n",
    "# X_train_pool = Pool(data=X_train_fd, label=y_train)\n",
    "# X_test_pool = Pool(data=X_test_fd, label=y_test)\n",
    "\n",
    "# cb.fit(X_train_pool)\n",
    "# y_pred = cb.predict(X_test_pool)\n",
    "# (abs(np.exp(y_pred) - np.exp(y_test))/np.exp(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0.08731439284984108,\n",
       " 'xgb': 0.08995599203531122,\n",
       " 'gb': 0.08994130906011347}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делаем фрейм из предиктов моделей\n",
    "y_pred_df = pd.DataFrame(y_pred_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем среднее значение\n",
    "y_pred_df['pred_mean'] = y_pred_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_blend = y_pred_df['pred_mean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_blend = (abs(np.exp(y_pred_blend) - np.exp(y_test))/np.exp(y_test)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем стекинг\n",
    "\n",
    "regressors = [\n",
    "    ('GBR', GradientBoostingRegressor(n_estimators=5000, max_depth=3, learning_rate=0.07, random_state=42)),\n",
    "    ('CATB', CatBoostRegressor(depth=7, iterations=10000, learning_rate=0.03, verbose=False, random_state=42)),\n",
    "]\n",
    "\n",
    "final_estimator = Ridge(alpha=50, max_iter=10000)\n",
    "# final_estimator = SVR(C=0.5)\n",
    "# final_estimator = XGBRegressor(n_estimators=200, max_depth=3, random_state=42)\n",
    "\n",
    "stack_regr = StackingRegressor(estimators=regressors, final_estimator=final_estimator)\n",
    "\n",
    "stack_regr.fit(X_train, y_train)\n",
    "y_pred = stack_regr.predict(X_test)\n",
    "\n",
    "# считаем наш кастомный mape, восстанавливая target из логарифма\n",
    "mape_stack = (abs(np.exp(y_pred) - np.exp(y_test))/np.exp(y_test)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending MAPE = 0.09045728421366735\n",
      "Stacking MAPE = 0.08735584783035397\n"
     ]
    }
   ],
   "source": [
    "print(f'Blending MAPE = {mape_blending}')\n",
    "print(f'Stacking MAPE = {mape_stack}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опционально можно посмотреть feature importances\n",
    "\n",
    "# importances = stack_regr.estimators_[2].feature_importances_\n",
    "# # encoded_features = encoder.get_feature_names()\n",
    "# # columns = numeric_features + list(encoded_features) + list(mean_columns)\n",
    "# columns = num_features + list(mean_columns) #+ list(encoder.get_feature_names()) \n",
    "# len(importances) - len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'cols':columns, 'val':importances}).sort_values('val', ascending=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДОПОЛНЕНИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно запустить Catboost через Pool - в целом тот же результат\n",
    "# Сделал проверку MAPE xthtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned_sample = X_cleaned.sample(frac=0.99, random_state=42)\n",
    "y_cleaned_sample = y_cleaned.sample(frac=0.99, random_state=42)\n",
    "\n",
    "X_cleaned_fd = FeaturesData(num_feature_data=X_cleaned_sample[numeric_features].values, \n",
    "                    cat_feature_data = X_cleaned_sample[cat_features].values,\n",
    "                    num_feature_names = numeric_features,\n",
    "                    cat_feature_names = cat_features)\n",
    "\n",
    "\n",
    "data_pool = Pool(data=X_cleaned_fd, label=y_cleaned_sample)\n",
    "reg = CatBoostRegressor()\n",
    "\n",
    "# Опять же - можено нельзя поставить кастомный scoring (или можно - но не знаю как)\n",
    "params = {\"iterations\": 10000,\n",
    "          \"depth\": 7,\n",
    "          \"learning_rate\": 0.045,\n",
    "          \"loss_function\": \"MAE\",\n",
    "          \"verbose\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cv(data_pool,\n",
    "            params,\n",
    "            fold_count=3, \n",
    "            plot=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка других моделей на кроссвалидации на встроенном MAE (который ввиду логарифмироания не имеет никакого\n",
    "# физического смысла, но уменьшать его можно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оооочень долго учится лес. Невыносимо, часа 4-5 на 10 000 деревьев\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "params = {\n",
    "    'n_estimators' : [5000],# 10000],\n",
    "    'max_depth' : [30],\n",
    "    'criterion' : ['mse']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# почему-то учится еще дольше, чем лес\n",
    "regressor = ExtraTreesRegressor(random_state=42)\n",
    "params = {\n",
    "    'n_estimators' : [300, 1000],# 5000],\n",
    "    'max_depth' : [100],\n",
    "    'criterion' : ['mae']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на удивления помогли деревья нестандартной глубины (глубина 7 работает лучше чем дефолтная 3) и нужно\n",
    "# много деревьев - 10 000 - лучший cross-val\n",
    "regressor = CatBoostRegressor()\n",
    "params = {'depth':[3, 6, 7, 8],\n",
    "          'iterations':[10000, 15000, 20000],\n",
    "          'learning_rate':[0.05, 0.07, 0.1]}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# долго и результат хуже, чем у Catboost\n",
    "\n",
    "regressor = GradientBoostingRegressor(random_state=42)\n",
    "params = {\n",
    "    'n_estimators' : [2000],\n",
    "    'max_depth' : [3],\n",
    "    'learning_rate' : [0.1, 0.2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Результат как у регрессий, но на больших данных SVR закончит вычисления \"никогда\" на моем ноутбуке\n",
    "\n",
    "regressor = SVR()\n",
    "params = {\n",
    "    'C': [0.25],\n",
    "    'kernel': ['linear'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# очень быстро, но результат хуже, чем у CatBoost - 0.155 против 0.125\n",
    "\n",
    "regressor = Lasso()\n",
    "params = {\n",
    "    'alpha': [7e-5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат чуть хуже, чем у Lasso\n",
    "\n",
    "regressor = Ridge()\n",
    "params = {\n",
    "    'alpha': [1.5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Слабее Lasso, Ridge\n",
    "\n",
    "regressor = LinearRegression()\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(regressor, param_grid=params, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "gs.fit(X, y_cleaned_sample)\n",
    "\n",
    "print(gs.best_params_)\n",
    "print(f'MAE = {-gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# записал рзультаты эстиматоров на кросс-валидации по MAE по логарифмированному target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Random Forest\n",
    "{'criterion': 'mse', 'max_depth': 30, 'n_estimators': 5000}\n",
    "MAE = 0.18613126948166414\n",
    "\n",
    "Extra Trees\n",
    "{'criterion': 'mae', 'max_depth': 100, 'n_estimators': 50}\n",
    "MAE = 0.17843565781992193\n",
    "\n",
    "Linear Regression\n",
    "{'fit_intercept': True}\n",
    "MAE = 0.16166042820598073\n",
    "\n",
    "Ridge\n",
    "{'alpha': 2}\n",
    "MAE = 0.1549745451687659\n",
    "\n",
    "Lasso\n",
    "{'alpha': 7e-05}\n",
    "MAE = 0.15383390684128465\n",
    "\n",
    "SVR\n",
    "{'C': 0.25, 'kernel': 'linear'}\n",
    "MAE = 0.15392866099694105\n",
    "\n",
    "GradientBoost\n",
    "{'max_depth': 5, 'n_estimators': 500}\n",
    "MAE = 0.1667841712619347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробовал стекинг - результат хуже, чем у отдельных моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    ('Ridge', Ridge(alpha=1.5)),\n",
    "    ('Lasso', Lasso(alpha=2)),\n",
    "    ('Linear', LinearRegression())\n",
    "]\n",
    "final_estimator = CatBoostRegressor(depth=7, iterations=10000, learning_rate=0.1)\n",
    "# final_estimator = RandomForestRegressor(max_depth=30, n_estimators=5000)\n",
    "# final_estimator = GradientBoostingRegressor(max_depth=7, n_estimators=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_regr = StackingRegressor(estimators=regressors, final_estimator=final_estimator, \n",
    "                                             cv=5, n_jobs=-1)\n",
    "mae = cross_val_score(estimator=stack_regr, X=X, y=y_cleaned_sample, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
